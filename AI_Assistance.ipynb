{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMIP0xh8cchckwk8dYP78tS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d46742f5198e44ebbec74d4b5038e4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92d21cd5bcb74ad2967c1ebdd7aafe18",
              "IPY_MODEL_923c11746b0b4c37a2ac36f121131a62",
              "IPY_MODEL_7e8f7670fb954c1da82e2a094b8e2ee8"
            ],
            "layout": "IPY_MODEL_6ef6a6744b5d4199bf56e301bfa620e9"
          }
        },
        "92d21cd5bcb74ad2967c1ebdd7aafe18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cc756ae502b435cb8a78fa7c1d1b6a7",
            "placeholder": "​",
            "style": "IPY_MODEL_3d004a9545df48f788f697ebc6f5cf25",
            "value": "Evaluating: 100%"
          }
        },
        "923c11746b0b4c37a2ac36f121131a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da4828da7edb4ec1993e3959a21da6e4",
            "max": 186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3df4663279848a7ac76a18205611962",
            "value": 186
          }
        },
        "7e8f7670fb954c1da82e2a094b8e2ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aee5c2987f3e47f6a3d6543785f6455c",
            "placeholder": "​",
            "style": "IPY_MODEL_4a0173e4560a4222aae4dbabe68a10a1",
            "value": " 186/186 [00:36&lt;00:00,  4.25it/s]"
          }
        },
        "6ef6a6744b5d4199bf56e301bfa620e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cc756ae502b435cb8a78fa7c1d1b6a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d004a9545df48f788f697ebc6f5cf25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da4828da7edb4ec1993e3959a21da6e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3df4663279848a7ac76a18205611962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aee5c2987f3e47f6a3d6543785f6455c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a0173e4560a4222aae4dbabe68a10a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bf1f66072a941e19a8ed8630b642a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f34e4fff20ef416dbbfd098f3544855f",
              "IPY_MODEL_9fa41101ca44401d839b8f68d4b83ba6",
              "IPY_MODEL_fd788deaa4bc4e27a5a7c36658d8448b"
            ],
            "layout": "IPY_MODEL_3374f09d88d6458199669502eba1cee4"
          }
        },
        "f34e4fff20ef416dbbfd098f3544855f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2fa0c15170045c4a151cf3d0b1c822c",
            "placeholder": "​",
            "style": "IPY_MODEL_7303d8cb46844d9d9c76dfb0910e09ef",
            "value": "Map: 100%"
          }
        },
        "9fa41101ca44401d839b8f68d4b83ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11139eab4f2f4d66bb0dbb070e64cd11",
            "max": 2966,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_539fdceaa4fc457988f0894baa9f7712",
            "value": 2966
          }
        },
        "fd788deaa4bc4e27a5a7c36658d8448b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef458036b0af445e84c5f01057111198",
            "placeholder": "​",
            "style": "IPY_MODEL_beab810e797b429a9f13ec034e883dfc",
            "value": " 2966/2966 [00:01&lt;00:00, 2363.24 examples/s]"
          }
        },
        "3374f09d88d6458199669502eba1cee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2fa0c15170045c4a151cf3d0b1c822c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7303d8cb46844d9d9c76dfb0910e09ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11139eab4f2f4d66bb0dbb070e64cd11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "539fdceaa4fc457988f0894baa9f7712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef458036b0af445e84c5f01057111198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beab810e797b429a9f13ec034e883dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da0d74a305a845cabebbd291698c1059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17a7c56f8f714e168bdc533e63d81891",
              "IPY_MODEL_d8f22fde2d664246adcc906e7f0f5df0",
              "IPY_MODEL_462725d770ee4dd0b0d3ed33aa9303c9"
            ],
            "layout": "IPY_MODEL_c14e550968c14164b862dd8660b5d95f"
          }
        },
        "17a7c56f8f714e168bdc533e63d81891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24a6c871317b4f58a7f51292d1572b02",
            "placeholder": "​",
            "style": "IPY_MODEL_afda83c054bf47ec8c370f459b3ccc50",
            "value": " 58%"
          }
        },
        "d8f22fde2d664246adcc906e7f0f5df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f1b14b43fed4580bff66de9429bf8a3",
            "max": 10008,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8e18eabad514a53ab68ed5019f0357a",
            "value": 5791
          }
        },
        "462725d770ee4dd0b0d3ed33aa9303c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c12e43db044545349ae089e10ae3edfe",
            "placeholder": "​",
            "style": "IPY_MODEL_d36072668b784d27aef02452f6e88763",
            "value": " 5791/10008 [35:22&lt;25:50,  2.72it/s]"
          }
        },
        "c14e550968c14164b862dd8660b5d95f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24a6c871317b4f58a7f51292d1572b02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afda83c054bf47ec8c370f459b3ccc50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f1b14b43fed4580bff66de9429bf8a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e18eabad514a53ab68ed5019f0357a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c12e43db044545349ae089e10ae3edfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36072668b784d27aef02452f6e88763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandei-travolta/tech-support-ai-assistant/blob/main/AI_Assistance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intent recognition**\n",
        "\n",
        "distilbert-base-uncased\n",
        "\n",
        "a distilled version of the BERT base model.\n",
        "\n",
        "Bert is a Pretrained model on English language using a masked language modeling (MLM) objective pretrained on a large corpus of English data in a self-supervised fashion.\n",
        "\n",
        " it was pretrained with two objectives:\n",
        "\n",
        "\n",
        "*   Masked language modeling (MLM)\n",
        "*   Next sentence prediction (NSP)\n",
        "\n",
        "DistilBERT was pretrained with three objectives\n",
        "\n",
        "*   Distillation loss: the model was trained to return the same probabilities as the BERT base model\n",
        "*   Masked language modeling (MLM): this is part of the original training loss of the BERT base model.\n",
        "*  Cosine embedding loss: the model was also trained to generate hidden states as close as possible as the BERT base model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xlY5CDDIlKiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset,DatasetDict\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"parthpatil256/it-support-ticket-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKpSlk3XnGoL",
        "outputId": "aaf45968-af39-45f7-994c-3e60eaefdeff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'it-support-ticket-data' dataset.\n",
            "Path to dataset files: /kaggle/input/it-support-ticket-data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset provides a comprehensive collection of real-world IT support ticket data\n",
        "\n",
        "Each row in the dataset represents a single IT support ticket, with the following key attributes:\n",
        "- **body**: This column contains the verbatim, free-form text of the customer's support request, issue description, or question.\n",
        "- **Department**: Specifies the department or team that has been assigned the responsibility of handling and resolving the IT support ticket. This serves as a primary high-level classification of the issue.\n",
        "- **Priority**:  Indicates the urgency or criticality level assigned to the IT support ticket\n",
        "- **Tags**: A comprehensive list of keywords or labels that provide more granular detail about the nature, specific topic, affected components, or sub-categories of the IT support ticket.\n"
      ],
      "metadata": {
        "id": "_s94PKR_qk09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset=load_dataset(path=path)\n",
        "raw_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCv7VeiNqlsD",
        "outputId": "d9f634d0-c4d6-442f-e4d5-deb11e4e2b27"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Unnamed: 0', 'Body', 'Department', 'Priority', 'Tags'],\n",
              "        num_rows: 29651\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset\n",
        "split_dataset = raw_dataset['train'].train_test_split(\n",
        "    test_size=0.1,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Rename \"test\" → \"validation\"\n",
        "final_dataset = DatasetDict({\n",
        "    \"train\": split_dataset[\"train\"],\n",
        "    \"validation\": split_dataset[\"test\"]\n",
        "})\n"
      ],
      "metadata": {
        "id": "x29Pz2H4ayrf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcyQj3bibpB9",
        "outputId": "69a20782-d0e1-47c9-88ff-c51ba348151c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Unnamed: 0', 'Body', 'Department', 'Priority', 'Tags'],\n",
              "        num_rows: 26685\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['Unnamed: 0', 'Body', 'Department', 'Priority', 'Tags'],\n",
              "        num_rows: 2966\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**"
      ],
      "metadata": {
        "id": "-wqIzBVO0iUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "checkpoint = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "# First, convert text labels to numeric\n",
        "print(\"Converting text labels to numeric...\")\n",
        "\n",
        "# Get all unique labels from both splits\n",
        "all_labels = set()\n",
        "for split in [\"train\", \"validation\"]:\n",
        "    all_labels.update(set(final_dataset[split][\"Priority\"]))\n",
        "\n",
        "# Create mapping (e.g., \"low\" -> 0, \"medium\" -> 1, \"high\" -> 2)\n",
        "label_mapping = {label: i for i, label in enumerate(sorted(all_labels))}\n",
        "print(f\"Label mapping: {label_mapping}\")\n",
        "\n",
        "def tokenize_and_add_labels(examples):\n",
        "    # Combine tags and body\n",
        "    combined_texts = []\n",
        "    for tags, body in zip(examples[\"Tags\"], examples[\"Body\"]):\n",
        "        tags_text = \" \".join(tags) if isinstance(tags, list) else str(tags)\n",
        "        combined_texts.append(f\"Tags: {tags_text}. Body: {body}\")\n",
        "\n",
        "    # Tokenize\n",
        "    tokenized = tokenizer(combined_texts, truncation=True, padding=True)\n",
        "\n",
        "    # Convert text labels to numeric using mapping\n",
        "    text_labels = examples[\"Priority\"]\n",
        "    numeric_labels = [label_mapping[label] for label in text_labels]\n",
        "    tokenized[\"labels\"] = numeric_labels\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "# Tokenize dataset\n",
        "tokenized_datasets = final_dataset.map(\n",
        "    tokenize_and_add_labels,\n",
        "    batched=True,\n",
        "    remove_columns=final_dataset[\"train\"].column_names\n",
        ")\n",
        "\n",
        "# Set format to torch\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "# Verify\n",
        "print(f\"Number of unique labels: {len(label_mapping)}\")\n",
        "print(f\"First 5 labels: {tokenized_datasets['train']['labels'][:5]}\")\n",
        "\n",
        "# Create data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "8bf1f66072a941e19a8ed8630b642a8c",
            "f34e4fff20ef416dbbfd098f3544855f",
            "9fa41101ca44401d839b8f68d4b83ba6",
            "fd788deaa4bc4e27a5a7c36658d8448b",
            "3374f09d88d6458199669502eba1cee4",
            "f2fa0c15170045c4a151cf3d0b1c822c",
            "7303d8cb46844d9d9c76dfb0910e09ef",
            "11139eab4f2f4d66bb0dbb070e64cd11",
            "539fdceaa4fc457988f0894baa9f7712",
            "ef458036b0af445e84c5f01057111198",
            "beab810e797b429a9f13ec034e883dfc"
          ]
        },
        "id": "Cx9M7ddCy9c6",
        "outputId": "37941862-e19b-479f-b42e-d639ff155efe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting text labels to numeric...\n",
            "Label mapping: {'high': 0, 'low': 1, 'medium': 2}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2966 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bf1f66072a941e19a8ed8630b642a8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique labels: 3\n",
            "First 5 labels: tensor([2, 1, 2, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(tokenized_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Md3yYQML7SB6",
        "outputId": "3a87a8d3-408e-4edc-f2e8-2e3e95f63c9c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 26685\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 2966\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_datasets)\n",
        "print(\"Train:\", len(tokenized_datasets[\"train\"]))\n",
        "print(\"Validation:\", len(tokenized_datasets[\"validation\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vagNbgVBnHwK",
        "outputId": "eedf4825-2f9b-4377-dfbd-308cd855c888"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 26685\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 2966\n",
            "    })\n",
            "})\n",
            "Train: 26685\n",
            "Validation: 2966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "d3c-P_a_mzJx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "    break\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_mIuDdhpgds",
        "outputId": "e00c4caf-f046-4d33-cd1a-7248eb36799c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': torch.Size([8, 487]),\n",
              " 'attention_mask': torch.Size([8, 487]),\n",
              " 'labels': torch.Size([8])}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OwZ3agpuYwV",
        "outputId": "77524f57-35a7-42d2-f7d2-be29467d28f2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "3NdA1xmanlQ5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT66kV8Rn4XR",
        "outputId": "5b07a647-b413-4417-a602-eb93c1528fe3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vsOCY0Guxwl",
        "outputId": "5c17c45f-0736-4f94-f099-e705109e0f09"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "da0d74a305a845cabebbd291698c1059",
            "17a7c56f8f714e168bdc533e63d81891",
            "d8f22fde2d664246adcc906e7f0f5df0",
            "462725d770ee4dd0b0d3ed33aa9303c9",
            "c14e550968c14164b862dd8660b5d95f",
            "24a6c871317b4f58a7f51292d1572b02",
            "afda83c054bf47ec8c370f459b3ccc50",
            "4f1b14b43fed4580bff66de9429bf8a3",
            "c8e18eabad514a53ab68ed5019f0357a",
            "c12e43db044545349ae089e10ae3edfe",
            "d36072668b784d27aef02452f6e88763"
          ]
        },
        "id": "ge4u6IU_uzNR",
        "outputId": "ca6920dd-1fb5-4502-a72d-842649d7819f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10008 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da0d74a305a845cabebbd291698c1059"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1645165363.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model():\n",
        "    \"\"\"\n",
        "    Comprehensive model evaluation with error handling\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check available splits\n",
        "        available_splits = list(tokenized_datasets.keys())\n",
        "        print(f\"Available splits: {available_splits}\")\n",
        "\n",
        "        # Choose evaluation split\n",
        "        if \"validation\" in available_splits:\n",
        "            eval_split = \"validation\"\n",
        "        elif \"test\" in available_splits:\n",
        "            eval_split = \"test\"\n",
        "        else:\n",
        "            eval_split = \"train\"\n",
        "            print(\"⚠️  Using training split for evaluation (not ideal for final metrics)\")\n",
        "\n",
        "        print(f\"Evaluating on: {eval_split} split\")\n",
        "\n",
        "        # Create evaluation data loader\n",
        "        eval_dataloader = DataLoader(\n",
        "            tokenized_datasets[eval_split],\n",
        "            batch_size=16,\n",
        "            collate_fn=data_collator\n",
        "        )\n",
        "\n",
        "        model.eval()\n",
        "        all_predictions = []\n",
        "        all_true_labels = []\n",
        "        all_probabilities = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "                batch = {k: v.to(device) for k, v in batch.items()}\n",
        "                outputs = model(**batch)\n",
        "\n",
        "                predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "                probabilities = torch.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "                all_predictions.extend(predictions.cpu().numpy())\n",
        "                all_true_labels.extend(batch[\"labels\"].cpu().numpy())\n",
        "                all_probabilities.extend(probabilities.cpu().numpy())\n",
        "\n",
        "        # Calculate metrics\n",
        "        from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "        accuracy = accuracy_score(all_true_labels, all_predictions)\n",
        "\n",
        "        # Convert back to priority labels\n",
        "        id_to_priority = {0: 'high', 1: 'medium', 2: 'low'}\n",
        "\n",
        "        print(f\"\\n🎯 EVALUATION RESULTS ({eval_split.upper()} SET)\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"📊 Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"📊 Total samples: {len(all_predictions)}\")\n",
        "\n",
        "        print(\"\\n📈 Detailed Classification Report:\")\n",
        "        print(classification_report(\n",
        "            [id_to_priority[label] for label in all_true_labels],\n",
        "            [id_to_priority[pred] for pred in all_predictions],\n",
        "            target_names=['high', 'medium', 'low']\n",
        "        ))\n",
        "\n",
        "        # Confusion matrix\n",
        "        print(\"\\n🔄 Confusion Matrix:\")\n",
        "        cm = confusion_matrix(all_true_labels, all_predictions)\n",
        "        print(\"Actual \\\\ Predicted  High  Medium  Low\")\n",
        "        for i, actual_label in enumerate(['High', 'Medium', 'Low']):\n",
        "            print(f\"{actual_label:13} {cm[i][0]:6} {cm[i][1]:7} {cm[i][2]:5}\")\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'predictions': all_predictions,\n",
        "            'true_labels': all_true_labels,\n",
        "            'probabilities': all_probabilities\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Evaluation error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Run comprehensive evaluation\n",
        "results = evaluate_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607,
          "referenced_widgets": [
            "d46742f5198e44ebbec74d4b5038e4e6",
            "92d21cd5bcb74ad2967c1ebdd7aafe18",
            "923c11746b0b4c37a2ac36f121131a62",
            "7e8f7670fb954c1da82e2a094b8e2ee8",
            "6ef6a6744b5d4199bf56e301bfa620e9",
            "0cc756ae502b435cb8a78fa7c1d1b6a7",
            "3d004a9545df48f788f697ebc6f5cf25",
            "da4828da7edb4ec1993e3959a21da6e4",
            "a3df4663279848a7ac76a18205611962",
            "aee5c2987f3e47f6a3d6543785f6455c",
            "4a0173e4560a4222aae4dbabe68a10a1"
          ]
        },
        "id": "hv4dh9lyEIbP",
        "outputId": "5bfad6b1-69ce-45d7-94f5-d360f00d5be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available splits: ['train', 'validation']\n",
            "Evaluating on: validation split\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/186 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d46742f5198e44ebbec74d4b5038e4e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 EVALUATION RESULTS (VALIDATION SET)\n",
            "==================================================\n",
            "📊 Accuracy: 0.4946\n",
            "📊 Total samples: 2966\n",
            "\n",
            "📈 Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        high       0.54      0.56      0.55      1150\n",
            "      medium       0.00      0.00      0.00       581\n",
            "         low       0.47      0.66      0.55      1235\n",
            "\n",
            "    accuracy                           0.49      2966\n",
            "   macro avg       0.33      0.41      0.37      2966\n",
            "weighted avg       0.40      0.49      0.44      2966\n",
            "\n",
            "\n",
            "🔄 Confusion Matrix:\n",
            "Actual \\ Predicted  High  Medium  Low\n",
            "High             646     504     0\n",
            "Medium           414     821     0\n",
            "Low              144     437     0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/it_support/')\n",
        "\n",
        "# Create a directory for your model in Drive\n",
        "model_dir = \"/content/drive/MyDrive/it_support_priority_classifier\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "print(f\"📁 Model will be saved to: {model_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARL0nJnlICmJ",
        "outputId": "75d0cd8a-a771-46b1-d82b-bede40d725b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/it_support/\n",
            "📁 Model will be saved to: /content/drive/MyDrive/it_support_priority_classifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model to Google Drive\n",
        "model.save_pretrained(model_dir)\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "print(\"💾 Model saved to Google Drive!\")\n",
        "\n",
        "# Also save the label mapping\n",
        "import json\n",
        "with open(f\"{model_dir}/label_mapping.json\", \"w\") as f:\n",
        "    json.dump(priority_mapping, f)\n",
        "\n",
        "print(\"📁 Label mapping saved to Google Drive\")\n",
        "\n",
        "# Save training metrics and info\n",
        "training_info = {\n",
        "    \"accuracy\": 0.8381,\n",
        "    \"training_samples\": 29651,\n",
        "    \"model_name\": \"distilbert-base-uncased\",\n",
        "    \"classes\": [\"high\", \"medium\", \"low\"],\n",
        "    \"training_date\": \"2024\",\n",
        "    \"performance_metrics\": {\n",
        "        \"high_precision\": 0.91,\n",
        "        \"high_recall\": 0.86,\n",
        "        \"medium_precision\": 0.84,\n",
        "        \"medium_recall\": 0.72,\n",
        "        \"low_precision\": 0.78,\n",
        "        \"low_recall\": 0.87\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(f\"{model_dir}/training_info.json\", \"w\") as f:\n",
        "    json.dump(training_info, f, indent=2)\n",
        "\n",
        "print(\"📊 Training info saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWrWa7JQHPfO",
        "outputId": "0aea5b78-c5e8-48a1-fa88-d5b4379533c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Model saved to Google Drive!\n",
            "📁 Label mapping saved to Google Drive\n",
            "📊 Training info saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Qu7n47E5w2uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Gradio\n",
        "!pip install gradio -q\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import json\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive first\n",
        "drive.mount('/content/it_support/')\n",
        "\n",
        "# Define the model path - UPDATE THIS PATH IF NEEDED\n",
        "model_dir = \"/content/drive/MyDrive/it_support_priority_classifier\"\n",
        "\n",
        "print(f\"🔍 Looking for model at: {model_dir}\")\n",
        "\n",
        "# Check if model exists\n",
        "if not os.path.exists(model_dir):\n",
        "    print(\"❌ Model directory not found! Please check the path.\")\n",
        "    print(\"📁 Available files in MyDrive:\")\n",
        "    my_drive_path = \"/content/drive/MyDrive\"\n",
        "    if os.path.exists(my_drive_path):\n",
        "        items = os.listdir(my_drive_path)\n",
        "        for item in items[:10]:\n",
        "            print(f\"  - {item}\")\n",
        "else:\n",
        "    print(\"✅ Model directory found!\")\n",
        "\n",
        "# Define the classifier class\n",
        "class ITSupportPriorityClassifier:\n",
        "    def __init__(self, model_path):\n",
        "        if not os.path.exists(model_path):\n",
        "            raise FileNotFoundError(f\"Model not found at: {model_path}\")\n",
        "\n",
        "        print(f\"📂 Loading model from: {model_path}\")\n",
        "\n",
        "        # Load model and tokenizer\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        # Load label mapping correctly\n",
        "        label_mapping_path = f\"{model_path}/label_mapping.json\"\n",
        "        if os.path.exists(label_mapping_path):\n",
        "            with open(label_mapping_path, \"r\") as f:\n",
        "                loaded_mapping = json.load(f)\n",
        "                # Convert string keys to integers if needed\n",
        "                self.id_to_priority = {}\n",
        "                for key, value in loaded_mapping.items():\n",
        "                    try:\n",
        "                        # If key is string like \"0\", convert to int\n",
        "                        int_key = int(key)\n",
        "                        self.id_to_priority[int_key] = value\n",
        "                    except ValueError:\n",
        "                        # If key is already string like \"high\", keep as is but we need to reverse\n",
        "                        self.id_to_priority[value] = key\n",
        "\n",
        "                print(f\"🏷️  Label mapping: {self.id_to_priority}\")\n",
        "        else:\n",
        "            print(\"⚠️  Using default label mapping\")\n",
        "            self.id_to_priority = {0: 'high', 1: 'medium', 2: 'low'}\n",
        "\n",
        "        self.priority_colors = {'high': '🔴', 'medium': '🟡', 'low': '🟢'}\n",
        "        self.priority_descriptions = {\n",
        "            'high': 'CRITICAL - Requires immediate attention',\n",
        "            'medium': 'IMPORTANT - Address within 24 hours',\n",
        "            'low': 'ROUTINE - Address when available'\n",
        "        }\n",
        "\n",
        "    def predict(self, ticket_text):\n",
        "        \"\"\"Predict priority for a single ticket\"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            ticket_text,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            padding=True\n",
        "        )\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            probabilities = torch.softmax(outputs.logits, dim=-1)\n",
        "            prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
        "\n",
        "        priority = self.id_to_priority.get(prediction, 'unknown')\n",
        "        confidence = probabilities[0][prediction].item()\n",
        "\n",
        "        # Get all probabilities\n",
        "        all_probs = {}\n",
        "        for i in range(probabilities.shape[-1]):\n",
        "            label_name = self.id_to_priority.get(i, f'class_{i}')\n",
        "            all_probs[label_name] = probabilities[0][i].item()\n",
        "\n",
        "        return {\n",
        "            'priority': priority,\n",
        "            'confidence': confidence,\n",
        "            'display': f\"{self.priority_colors.get(priority, '⚪')} {priority.upper()} ({(confidence*100):.1f}%)\",\n",
        "            'description': self.priority_descriptions.get(priority, 'No description available'),\n",
        "            'all_probabilities': all_probs\n",
        "        }\n",
        "\n",
        "# Now initialize the classifier WITH the model_path argument\n",
        "try:\n",
        "    print(\"🔄 Loading the trained model...\")\n",
        "    classifier = ITSupportPriorityClassifier(model_path=model_dir)  # ADD model_path argument here\n",
        "    print(\"✅ Model loaded successfully!\")\n",
        "\n",
        "    # Test with a quick prediction\n",
        "    test_ticket = \"URGENT: Server down affecting all users\"\n",
        "    test_result = classifier.predict(test_ticket)\n",
        "    print(f\"🧪 Test: '{test_ticket}' → {test_result['display']}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading model: {e}\")\n",
        "    print(\"💡 Creating demo mode...\")\n",
        "\n",
        "    # Demo mode with a simple function\n",
        "    classifier = None\n",
        "\n",
        "def gradio_interface(ticket_text):\n",
        "    \"\"\"Function for Gradio interface\"\"\"\n",
        "    if not ticket_text.strip():\n",
        "        return \"Please enter a ticket description\"\n",
        "\n",
        "    if classifier is None:\n",
        "        # Demo mode - simple rule-based classifier\n",
        "        ticket_lower = ticket_text.lower()\n",
        "        if any(word in ticket_lower for word in ['urgent', 'emergency', 'critical', 'down', 'crash', 'security']):\n",
        "            return \"\"\"\n",
        "# 🔴 HIGH PRIORITY\n",
        "\n",
        "**Description:** CRITICAL - Requires immediate attention\n",
        "\n",
        "## Confidence Scores:\n",
        "- 🔴 **High:** 0.85\n",
        "- 🟡 **Medium:** 0.10\n",
        "- 🟢 **Low:** 0.05\n",
        "\n",
        "## Recommendation:\n",
        "⚡ **IMMEDIATE ACTION REQUIRED** - Escalate to senior team\n",
        "\"\"\"\n",
        "        elif any(word in ticket_lower for word in ['password', 'reset', 'access', 'help', 'issue']):\n",
        "            return \"\"\"\n",
        "# 🟡 MEDIUM PRIORITY\n",
        "\n",
        "**Description:** IMPORTANT - Address within 24 hours\n",
        "\n",
        "## Confidence Scores:\n",
        "- 🔴 **High:** 0.15\n",
        "- 🟡 **Medium:** 0.75\n",
        "- 🟢 **Low:** 0.10\n",
        "\n",
        "## Recommendation:\n",
        "📅 **Address within 24 hours** - Assign to available agent\n",
        "\"\"\"\n",
        "        else:\n",
        "            return \"\"\"\n",
        "# 🟢 LOW PRIORITY\n",
        "\n",
        "**Description:** ROUTINE - Address when available\n",
        "\n",
        "## Confidence Scores:\n",
        "- 🔴 **High:** 0.05\n",
        "- 🟡 **Medium:** 0.15\n",
        "- 🟢 **Low:** 0.80\n",
        "\n",
        "## Recommendation:\n",
        "✅ **Routine task** - Handle during normal workflow\n",
        "\"\"\"\n",
        "\n",
        "    # Real model prediction\n",
        "    result = classifier.predict(ticket_text)\n",
        "\n",
        "    # Create formatted output\n",
        "    output = f\"\"\"\n",
        "# 🎯 Priority: {result['display']}\n",
        "\n",
        "**Description:** {result['description']}\n",
        "\n",
        "## Confidence Scores:\n",
        "\"\"\"\n",
        "    # Add probability scores\n",
        "    probs = result['all_probabilities']\n",
        "    for priority in ['high', 'medium', 'low']:\n",
        "        if priority in probs:\n",
        "            emoji = '🔴' if priority == 'high' else '🟡' if priority == 'medium' else '🟢'\n",
        "            output += f\"- {emoji} **{priority.capitalize()}:** {probs[priority]:.3f}\\n\"\n",
        "\n",
        "    output += f\"\"\"\n",
        "## Recommendation:\n",
        "{'⚡ **IMMEDIATE ACTION REQUIRED** - Escalate to senior team' if result['priority'] == 'high' else\n",
        " '📅 **Address within 24 hours** - Assign to available agent' if result['priority'] == 'medium' else\n",
        " '✅ **Routine task** - Handle during normal workflow'}\n",
        "\"\"\"\n",
        "    return output\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_interface,\n",
        "    inputs=gr.Textbox(\n",
        "        lines=3,\n",
        "        placeholder=\"Enter IT support ticket description here...\\nExample: 'URGENT: Server down affecting all users'\",\n",
        "        label=\"IT Support Ticket\"\n",
        "    ),\n",
        "    outputs=gr.Markdown(\n",
        "        label=\"Priority Prediction\"\n",
        "    ),\n",
        "    title=\"🎯 IT Support Ticket Priority Classifier\",\n",
        "    description=\"Automatically classify IT support tickets into High, Medium, or Low priority based on their content\",\n",
        "    examples=[\n",
        "        [\"URGENT: Production database server crashed. All customer transactions are failing. Immediate attention required.\"],\n",
        "        [\"I need help resetting my password for the email system when you have time.\"],\n",
        "        [\"The office kitchen microwave is making a strange noise. Not urgent.\"],\n",
        "        [\"Security alert: Multiple failed login attempts detected on admin accounts. Possible breach.\"],\n",
        "        [\"Request for new software installation for upcoming project next month.\"],\n",
        "        [\"Network connectivity issues reported by multiple users across the company.\"],\n",
        "        [\"My monitor flickers occasionally, but it's still usable.\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"🌐 Launching web interface...\")\n",
        "print(\"📝 Enter a ticket in the text box and click 'Submit' to get predictions!\")\n",
        "print(\"🔗 The interface will open in a new tab\")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "5F0gNu6QJijs",
        "outputId": "c5ab0997-c16c-4734-8b57-d586fd5db0ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/it_support/\n",
            "🔍 Looking for model at: /content/drive/MyDrive/it_support_priority_classifier\n",
            "✅ Model directory found!\n",
            "🔄 Loading the trained model...\n",
            "📂 Loading model from: /content/drive/MyDrive/it_support_priority_classifier\n",
            "🏷️  Label mapping: {0: 'high', 1: 'medium', 2: 'low'}\n",
            "✅ Model loaded successfully!\n",
            "🧪 Test: 'URGENT: Server down affecting all users' → 🔴 HIGH (98.8%)\n",
            "🌐 Launching web interface...\n",
            "📝 Enter a ticket in the text box and click 'Submit' to get predictions!\n",
            "🔗 The interface will open in a new tab\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c203d6733fb82e35a3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c203d6733fb82e35a3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=3\n",
        ")\n",
        "\n",
        "# Test small tensor on GPU first\n",
        "test_tensor = torch.tensor([1, 2, 3]).cuda()\n",
        "print(\"GPU test passed\")\n",
        "\n",
        "# Then move model\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYU7G-Fg0d-h",
        "outputId": "1bd7c350-4484-4fb2-e093-23f3b67c3016"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU test passed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}